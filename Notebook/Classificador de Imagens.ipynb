{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMXI/Trv51LkCjZUrHxzqUm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Classificação de Imagens\n","\n","\n","Neste módulo é possível acompanhar a implementação de um processo de classificação de imagens utilizando técnicas clássicas de Processamento Digital de Imagens e treinar classificadores para predição dos atributos.\n","\n","Módulos necessários"],"metadata":{"id":"QkW51tkbRj-t"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"Rup_-_pLReZy","executionInfo":{"status":"ok","timestamp":1666460536311,"user_tz":180,"elapsed":2789,"user":{"displayName":"Marcelo De Araújo","userId":"09818702720801996007"}}},"outputs":[],"source":["import os\n","import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","from random import shuffle\n","from sklearn.model_selection import train_test_split\n","from sklearn import metrics,svm\n","from sklearn.metrics import classification_report\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn import tree\n","from skimage.measure import regionprops\n","from skimage.filters import threshold_otsu\n","from sklearn.preprocessing import MaxAbsScaler"]},{"cell_type":"markdown","source":["\n","Preparando o dataset \n","\n","\n","Neste primeiro momento há necessidade de observar as imagens do dataset e organizá-las em uma estrutura de dados adequada para que seus atributos possam ser extraídos. há então a necessidade de carregar o conjunto de imagens via código. Abaixo segue um exemplo de uma função para carregar o conjunto de imagens e retornar estas estruturadas em lista e outra lista indicando classe de cada imagem.\n","\n"],"metadata":{"id":"qPl3_OduRwNA"}},{"cell_type":"code","source":["def load_data(datadir, classes, img_size=100):\n","    training_data = []\n","    label = []\n","    for classe in range(len(classes)):\n","        path = os.path.join(datadir, classes[classe])\n","        shufled_list  = list(os.listdir(path))\n","        shuffle(shufled_list)\n","        for img in shufled_list:\n","            img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n","            img_array = cv2.resize(img_array, (img_size, img_size))\n","            unique = np.unique(img_array)\n","            if len(unique) == 1:\n","                continue\n","            training_data.append(img_array)\n","            label.append(classe)\n","    return training_data , label"],"metadata":{"id":"pdnQd6UzRwo0","executionInfo":{"status":"ok","timestamp":1666460536313,"user_tz":180,"elapsed":7,"user":{"displayName":"Marcelo De Araújo","userId":"09818702720801996007"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["data , label = load_data('dataset/geometric',['circle','square','star','triangle'])"],"metadata":{"id":"_IbIhnD6SGZ0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["O código acima realiza a implementação de uma função que recebe 3 argumentos: o diretório que contem as pastas das imagens, uma lista de string que contém o nome das classes que devem ser reconhecidas e um parâmetro default que é o  tamanho da imagem que será utilizado em todo o processo. \n","\n","\n","São definidas duas listas vazias training_data e label. Em training_data serão armazenadas as imagens e em label serão definidos números que representam cada classe.Deste modo, é possível saber a classe da imagem que estiver na posição 5 da lista training_data observando o número contido da quinta posição da lista label.\n","\n","\n","Um loop for é realizado para iterar sobre as possíveis classes. Assim a variável classe,definida no loop, poderá assumir valores variando de  0 até 3, em que 0 representa classe 'circle' e 3 representa a classe 'triangle'. Na variável path é armazenada a string que contem o caminho para pasta de imagens da classe específica, conforme iteração do loop for e na estrutura shufled_list são contidas strings que são os caminhos de cada imagem da classe, já com um primeiro embaralhamento.\n","O segundo loop for itera sobre os caminhos das imagens específicas e armazena estas em tom de cinza na variável img_array. A imagem é redimensionada, armazenada na lista training_data e variável classe é armazenada na lista label. Foi observado inconsistências neste dataset específico, em que há casos de imagens com um único tom de cinza. Estas são descartadas através da verificação junto a função unique da numpy auxiliada pelo comando if."],"metadata":{"id":"3qK1IL_fSDGl"}},{"cell_type":"code","source":["def get_contours_param(contour):\n","    contour_area = contour[0].filled_area\n","    contour_perimeter = contour[0].perimeter\n","    contour_convex_area = contour[0].convex_area\n","    diameter = contour[0].equivalent_diameter\n","    return contour_area , contour_perimeter, contour_convex_area, diameter"],"metadata":{"id":"juqxy3paSZJz","executionInfo":{"status":"ok","timestamp":1666460540918,"user_tz":180,"elapsed":378,"user":{"displayName":"Marcelo De Araújo","userId":"09818702720801996007"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def features_extraction(images):\n","    features_list = []\n","    for image in images:\n","        thresh = threshold_otsu(image)\n","        binary = np.array(image > thresh).astype(int)\n","        white_pixel = np.where(binary > 0)\n","        if len(white_pixel[0]) > 7000:\n","            binary = abs(1-binary) # ajuste de imagens negativas\n","        regions = regionprops(binary)\n","        contour_area , contour_perimeter, contour_convex_area, diameter = get_contours_param(regions)\n","        features_list.append([contour_area , contour_perimeter, contour_convex_area, diameter])\n","    norm =  MaxAbsScaler()\n","    norm.fit(features_list)\n","    norm_features = norm.transform(features_list)\n","    return norm_features"],"metadata":{"id":"GhXnJPjvSgIJ","executionInfo":{"status":"ok","timestamp":1666460542545,"user_tz":180,"elapsed":6,"user":{"displayName":"Marcelo De Araújo","userId":"09818702720801996007"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["features = features_extraction(data)"],"metadata":{"id":"AHk53cPeSjuo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Nesta etapa, features_extraction recebe a lista de imagens que foi obtida em load_data. Nesta função é aplicada a limiarização de Otsu de forma iterativa com auxílio do loop for. Neste caso de imagens sintéticas, existe a possibilidade de o processo de limiarização de Otsu gerar imagens binarizadas, mas algumas sendo negativas. Assim é realizado a contagem de pixels brancos para garatir que estes componham o objeto e não o plano de fundo. Essa análise é específica para este dataset em particular. Essa lógica está implementada na analíse de white_pixels. Por isso, quando são contabilizados mais que 7000 pixels brancos, sugere-se que há caso de limiarização negativa.\n","\n","\n","\n","\n","o Método regionprops é utilizado para segmentar as regiões geométricas da imagem. Contexto, a função get_contours_param é implementada para extrair os atributos do contorno. Ative o modo DEBUG da sua IDE para poder observar outros atributos que podem ser extraídos.\n","\n","\n","\n","\n","Por fim, é realizada a normalização dos atributos para dimensionar cada atributo individualmente de modo que o valor absoluto máximo de cada um no conjunto de treinamento seja 1,0. A função MaxAbsScaler realiza isso."],"metadata":{"id":"D1w3W1zDSqnx"}},{"cell_type":"code","source":[],"metadata":{"id":"NL8cK659S3qr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Treinamento e Teste dos Classificadores.\n","\n","\n","A variável features possui as os atributos extraídos das imagens. Neste contexto, a função gen_classifiers é iamplementada para retornar testes em 7 classificadores: \n","\n","Random Forest, \n","MLP, \n","KNN, \n","SGDC, \n","SVM, \n","Árvore de decisão, \n","Naive Bayes."],"metadata":{"id":"ZG6d62_sSxqj"}},{"cell_type":"code","source":["def generate_svm_model(train_data,label_train_data,test_data):\n","    clf = svm.SVC(kernel='linear')\n","    clf.fit(train_data, label_train_data)\n","    predicted = clf.predict(test_data)\n","    return predicted\n","def generate_SGDC_model(train_data,label_train_data,test_data):\n","    clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=200)\n","    clf.fit(train_data, label_train_data)\n","    predicted = clf.predict(test_data)\n","    return predicted\n","def generate_naive_bayes_model(train_data,label_train_data,test_data):\n","    gnb = GaussianNB()\n","    gnb.fit(train_data, label_train_data)\n","    predicted = gnb.predict(test_data)\n","    return predicted\n","def generate_decision_tree_model(train_data,label_train_data,test_data):\n","    clf = tree.DecisionTreeClassifier()\n","    clf = clf.fit(train_data, label_train_data)\n","    predicted = clf.predict(test_data)\n","    return predicted\n","def generate_random_forest_model(X_train, y_train,test_data):\n","    rfc = RandomForestClassifier(criterion= 'entropy', max_depth= 8, max_features='auto', n_estimators=200)\n","    rfc.fit(X_train,y_train)\n","    predicted = rfc.predict(test_data)\n","    return predicted\n","def generate_MLP_model(X_train, y_train,test_data):\n","    classifier = MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=300,activation = 'relu',solver='adam',random_state=1)\n","    classifier.fit(X_train, y_train)\n","    predicted = classifier.predict(test_data)\n","    return predicted\n","def generate_knn_model(train_data,label_train_data,test_data):\n","    knn = KNeighborsClassifier()\n","    knn.fit(train_data,label_train_data)\n","    predicted = knn.predict(test_data)\n","    return predicted"],"metadata":{"id":"Zg4ueTAXSta-","executionInfo":{"status":"ok","timestamp":1666460556791,"user_tz":180,"elapsed":397,"user":{"displayName":"Marcelo De Araújo","userId":"09818702720801996007"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def gen_classifiers(train_data,label_train_data,test_data):\n","    return generate_knn_model(train_data,label_train_data,test_data),\\\n","    generate_MLP_model(train_data,label_train_data,test_data),\\\n","    generate_SGDC_model(train_data,label_train_data,test_data),\\\n","    generate_svm_model(train_data,label_train_data,test_data),\\\n","    generate_decision_tree_model(train_data,label_train_data,test_data),\\\n","    generate_naive_bayes_model(train_data,label_train_data,test_data),\\\n","    generate_random_forest_model(train_data,label_train_data,test_data),\n"],"metadata":{"id":"l-stvGbrTJEN","executionInfo":{"status":"ok","timestamp":1666460562314,"user_tz":180,"elapsed":427,"user":{"displayName":"Marcelo De Araújo","userId":"09818702720801996007"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["X_train,X_test,y_train,y_test = train_test_split(features,label,test_size=0.3)\n","results = gen_classifiers(X_train, y_train,X_test)"],"metadata":{"id":"V5OhnXveTMzT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A função divide o conjunto de atributos e labels em conjuntos de treino e teste para garantirmos que o processo de treinamento seja realizado com dados distintos dos que vão ser testados por cada classificador.\n","\n","Deste modo, a função gen_classifiers recebe os atributos de treinamento, as labels dos atributos de treinamento e os atribiutos de teste e retorna um array de valores que indicam os resultados dos testes de cada classificador. Cada classificador é inicializado com um objeto específico. Após a inicialização é realizado o comando fit para treinar o classificadorque recebe os atribiutos de treinamento e as labels dos atributos. Após o treinamento é realizado o comando predict para testar se o classificador realiza uma predição correta de atributos que não foram utilizados no conjunto de treinamento. A variável predicted é um vetor em que cada elemento do vetor é um valor que indica a classe a qual o atributo pertence. "],"metadata":{"id":"_3Vb8m6hTcVE"}},{"cell_type":"code","source":[],"metadata":{"id":"G5iC0telTfG5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Avaliação dos classificadores\n","\n","\n","A biblioteca sklearn possui funções que auxiliam a medir quantitativamente o desempenho do classificador. A acurácia do classificador pode ser medida pela chamada da função seguinte:\n","\n"],"metadata":{"id":"LFnkgS4VTg0i"}},{"cell_type":"code","source":["acc = metrics.accuracy_score(test_labels,predicted)"],"metadata":{"id":"0jl3ZPglTk5y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","VP = Verdadeiro positivo - objeto pertence a classe A e foi classificado na classe A\n","\n","VN = Verdadeiro negativo - objeto não pertence a classe A e não foi classificado na classe A\n","\n","FP = Falso positivo - objeto não pertence a classe A e foi classificado na classe A\n","\n","FN = Falso negativo - objeto pertence a classe A e não foi classificado na classe A\n","\n","A sensibilidade/revocação/recall do classificador, por classe,  pode ser medida pela chamada da função seguinte:"],"metadata":{"id":"DkBHmhtXTvDY"}},{"cell_type":"code","source":["recall = metrics.recall_score(y_test,results[0],average=None)"],"metadata":{"id":"1LbaxKN6Twbr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A precisão  do classificador, por classe,  pode ser medida pela chamada da função seguinte:\n","\n"],"metadata":{"id":"PWahqV2fT4tD"}},{"cell_type":"code","source":["precision = metrics.precision_score(y_test,results[0],average=None)"],"metadata":{"id":"4e34345eT5hb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A métrica F1-Score do classificador, por classe,  pode ser medida pela chamada da função seguinte:\n","\n"],"metadata":{"id":"docaZ0CwT7zg"}},{"cell_type":"code","source":["precision = metrics.precision_score(y_test,results[0],average=None)"],"metadata":{"id":"KHxdfmJ8UBaX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Acurácia: indica uma performance geral do modelo.Dentre todas as classificações, quantas o modelo classificou corretamente;\n","\n","Precisão: dentre todas as classificações de classe Positivo que o modelo fez, quantas estão corretas;\n","\n","Recall/Revocação/Sensibilidade: dentre todas as situações de classe Positivo como valor esperado, quantas estão corretas;\n","\n","F1-Score: média harmônica entre precisão e recall."],"metadata":{"id":"_HEkT5lDUHdV"}}]}