{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPYhOAjPAX+zdsjuWYQB0Yo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Tutorial Opencv\n","\n","\n","Este tutorial apresenta conceitos introdutórios de processamento de imagens (filtros) e de visão computacional (segmentação, classificação, reconhecimento de padrão e rastreamento). Estes conceitos serão introduzidos utilizando a biblioteca OpenCV, que é distribuída gratuitamente e possui documentação farta na internet, com exemplos e aplicações práticas. Para utilizar essa biblioteca em python acesse o terminal com ambiente de python ativado e digite pip install opencv-python."],"metadata":{"id":"9FSzueRuqcCC"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"PgA-4C9RqX46"},"outputs":[],"source":["# Importação das bibliotecas\n","import cv2\n","# Leitura da imagem com a função imread()\n","imagem = cv2.imread('entrada.jpg')\n","print('Largura em pixels: ', end='')\n","print(imagem.shape[1])\n","#largura da imagem print('Altura em pixels: ', end='')\n","print(imagem.shape[0])\n","#altura da imagem\n","print('Qtde de canais: ', end='')\n","print(imagem.shape[2])\n","# Mostra a imagem com a função imshow\n","cv2.imshow(\"Nome da janela\", imagem)\n","cv2.waitKey(0) #espera pressionar qualquer tecla\n","# Salvar a imagem no disco com função imwrite()\n","cv2.imwrite(\"saida.jpg\", imagem)"]},{"cell_type":"markdown","source":["Este  programa  abre  uma  imagem,  mostra  suas  propriedades  de  largura  e  altura  em pixels, mostra a quantidade de canais utilizados, mostra a imagem na tela, espera o pressionar de  alguma tecla  para  fechar  a  imagem  e  salva  em  disco  a  mesma  imagem  com  o  nome ‘saída.jpg’. Vamos explicar o código em detalhes abaixo: \n","\n"],"metadata":{"id":"QXHvDb4fqiAU"}},{"cell_type":"code","source":["# Importação das bibliotecas  \n","import cv2   \n","# Leitura da imagem com a função imread()  \n","imagem = cv2.imread('entrada.jpg')  "],"metadata":{"id":"TKLEcs1VquSR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A partir do entendimento do sistema de coordenadas é possível alterar individualmente cada pixel ou ler a informação individual do pixel conforme abaixo: "],"metadata":{"id":"NI__AhHhqwcR"}},{"cell_type":"code","source":["import cv2 \n","imagem = cv2.imread('ponte.jpg') \n","(b, g, r) = imagem[0, 0] #veja que a ordem BGR e não RGB "],"metadata":{"id":"8DVkOFq2qxGZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Imagens são matrizes Numpy neste caso retornadas pelo método “imread” e armazenada em memória através da variável “imagem” conforme acima. Lembre-se que o pixel superior mais a esquerda é o (0,0). No código é retornado na tupla (b, g, r) os respectivos valores das cores do pixel superior mais a esquerda. Veja que o método retorna a sequência BGR e não RGB como poderiamos esperar. Tendo os valores inteiros de cada cor é possível exibi-los na tela com o código abaixo:"],"metadata":{"id":"XvPJnWzjq6CD"}},{"cell_type":"code","source":["print('O pixel (0, 0) tem as seguintes cores:') \n","print('Vermelho:', r, 'Verde:', g, 'Azul:', b)  "],"metadata":{"id":"Mx6pNS_gq-Ih"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Outra possibilidade é utilizar dois laços de repetição para “varrer” todos os pixels da  imagem, linha por linha como é o caso do código abaixo. Importante notar que esta estratégia\n","pode  não  ser  muito  performática  já  que  é  um  processo  lento  varrer  toda  a  imagem  pixel  a pixel."],"metadata":{"id":"S5Gw32qprFlF"}},{"cell_type":"code","source":["import cv2 \n","imagem = cv2.imread('ponte.jpg') \n","for y in range(0, imagem.shape[0]):\n","   for x in range(0, imagem.shape[1]):\n","     imagem[y, x] = (255,0,0)\n","cv2.imshow(\"Imagem modificada\", imagem) "],"metadata":{"id":"y0I_6P9krGoA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Com uma  modificação temos o código abaixo. O objetivo agora é saltar  a cada 10 pixels ao percorrer as linhas e mais 10 pixels ao percorrer as colunas. A cada salto é criado um quadrado amarelo de 5x5 pixels. Desta vez parte da imagem original é preservada e  podemos ainda observar a ponte por baixo da grade de quadrados amarelos. "],"metadata":{"id":"O3-kDvtdrMIX"}},{"cell_type":"code","source":["import cv2 \n","imagem = cv2.imread('ponte.jpg') \n","for y in range(0, imagem.shape[0], 10): #percorre linhas\n","   for x in range(0, imagem.shape[1], 10): #percorre colunas\n","     imagem[y:y+5, x: x+5] = (0,255,255)\n","cv2.imshow(\"Imagem modificada\", imagem) \n","cv2.waitKey(0)  "],"metadata":{"id":"s-mPOwzsrNCr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Veja  o  código  abaixo onde criamos uma nova imagem a partir de um pedaço da imagem original (ROI) e a salvamos no\n","disco."],"metadata":{"id":"IVKNgxlVrPjW"}},{"cell_type":"code","source":["import cv2\n","imagem = cv2.imread('ponte.jpg')\n","recorte = imagem[100:200, 100:200]\n","cv2.imshow(\"Recorte da imagem\", recorte)\n","cv2.imwrite(\"recorte.jpg\", recorte) #salva no disco "],"metadata":{"id":"UULVivgOrU02"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Redimensionamento / Resize\n","\n","\n","Para  reduzir  ou  aumentar  o  tamanho  da  imagem,  existe  uma  função  já  pronta  da OpenCV, trata-se da função ‘resize’ mostrada abaixo. Importante notar que é preciso calcular\n","a proporção da altura em relação a largura da nova imagem, caso contrário ela poderá ficar distorcida."],"metadata":{"id":"S7EBJqzvrcNf"}},{"cell_type":"code","source":["import numpy as np\n","import cv2\n","img = cv2.imread('ponte.jpg')\n","cv2.imshow(\"Original\", img)\n","largura = img.shape[1]\n","altura = img.shape[0]\n","proporcao = float(altura/largura)\n","largura_nova = 320 #em pixels\n","altura_nova = int(largura_nova*proporcao)\n","tamanho_novo = (largura_nova, altura_nova)\n","img_redimensionada = cv2.resize(img,\n","tamanho_novo, interpolation = cv2.INTER_AREA)\n","cv2.imshow('Resultado', img_redimensionada)\n","cv2.waitKey(0) "],"metadata":{"id":"_JU_Om9GreLA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Espelhando uma imagem / Flip  \n","\n","\n","Para espelhar uma imagem, basta inverter suas linhas, suas colunas ou ambas. Invertendo as linhas temos o flip horizontal e invertendo as colunas temos o flip vertical.\n","Podemos fazer o espelhamento/flip tanto com uma função oferecida pela OpenCV (função flip) como através da manipulação direta das matrizes que compõe a imagem. Abaixo\n","temos os dois códigos equivalentes em cada caso."],"metadata":{"id":"NwrcgbYRrgv2"}},{"cell_type":"code","source":["import cv2 img = cv2.imread('ponte.jpg') \n","cv2.imshow(\"Original\", img) \n","flip_horizontal = img[::-1,:]#comando equivalente abaixo \n","#flip_horizontal = cv2.flip(img, 1)  \n","cv2.imshow(\"Flip Horizontal\", flip_horizontal) \n","flip_vertical = img[:,::-1] #comando equivalente abaixo \n","#flip_vertical = cv2.flip(img, 0)  \n","cv2.imshow(\"Flip Vertical\", flip_vertical) \n","flip_hv = img[::-1,::-1] #comando equivalente abaixo  \n","#flip_hv = cv2.flip(img, -1) \n","cv2.imshow(\"Flip Horizontal e Vertical\", flip_hv) \n","cv2.waitKey(0) "],"metadata":{"id":"rWNmtGPYrlwr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Rotacionando uma imagem / Rotate  \n","\n","\n","A  transformação  affine  ou  mapa  affine,  é  uma  função  entre  espaços  affine  que preservam  os  pontos,  grossura  de  linhas  e  planos.  Além  disso,  linhas  paralelas  permanecem\n","paralelas após uma transformação affine. Essa transformação não necessariamente preserva a distância entre pontos mas ela preserva a proporção das distâncias entre os pontos de uma\n","linha reta. Uma rotação é um tipo de transformação affine. "],"metadata":{"id":"klFMi0_drrPc"}},{"cell_type":"code","source":["img = cv2.imread('ponte.jpg') \n","(alt, lar) = img.shape[:2] #captura altura e largura \n","centro = (lar // 2, alt // 2) #acha o centro  \n","M = cv2.getRotationMatrix2D(centro, 30, 1.0)#30 graus \n","img_rotacionada = cv2.warpAffine(img, M, (lar, alt))  \n","cv2.imshow(\"Imagem rotacionada em 30 graus\", img_rotacionada) \n","cv2.waitKey(0)\n","  "],"metadata":{"id":"Kt0YBzIArsqo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Sistemas de cores \n","\n","\n","\n","Já  conhecemos  o  tradicional  espaço  de  cores  RGB  (Red,  Green,  Blue)  que  sabemos que  em  OpenCV  é  na  verdade  BGR  dada  a  necessidade  de  colocar  o  azul  como  primeiro elemento e o vermelho como terceiro elemento de uma tupla que compõe as cores de pixel.  \n","\n","Contudo, existem outros espaços de cores como o próprio “Preto e Branco” ou “tons de cinza”, além de outros coloridos como o L*a*b* e o HSV. Abaixo temos um exemplo de\n","como ficaria nossa imagem da ponte nos outros espaços de cores :"],"metadata":{"id":"4Bi4C8Hmrygj"}},{"cell_type":"code","source":["img = cv2.imread('ponte.jpg')\n","cv2.imshow(\"Original\", img)\n","gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","cv2.imshow(\"Gray\", gray)\n","hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n","cv2.imshow(\"HSV\", hsv)\n","lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n","cv2.imshow(\"L*a*b*\", lab)\n","cv2.waitKey(0) "],"metadata":{"id":"InRpZofBr0Nr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Como  já  sabemos  uma  imagem  colorida  no  formato  RGB  possui  3  canais,  um  para cada  cor.  Existem  funções  do  OpenCV  que  permitem  separar  e  visualizar  esses  canais\n","individualmente. Veja: \n","\n"],"metadata":{"id":"TteYkKKwr3OJ"}},{"cell_type":"code","source":["img = cv2.imread('ponte.jpg') \n","(canalAzul, canalVerde, canalVermelho) = cv2.split(img)\n","cv2.imshow(\"Vermelho\", canalVermelho) \n","cv2.imshow(\"Verde\", canalVerde) \n","cv2.imshow(\"Azul\", canalAzul) \n","cv2.waitKey(0) "],"metadata":{"id":"NseHThKur5zw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Também é possível alterar individualmente as Numpy Arrays que formam cada canal e depois juntá-las para criar novamente a imagem. Para isso use o comando: "],"metadata":{"id":"yzBjMnuRsCDp"}},{"cell_type":"code","source":["resultado = cv2.merge([canalAzul, canalVerde, canalVermelho]) "],"metadata":{"id":"RVrx7_upsDBm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Também é possível exibir os canais nas cores originais conforme abaixo:  \n","\n"],"metadata":{"id":"aEZNKD5hsFZI"}},{"cell_type":"code","source":["import numpy as np \n","import cv2 \n","img = cv2.imread('ponte.jpg')  \n","(canalAzul, canalVerde, canalVermelho) = cv2.split(img)  \n","zeros = np.zeros(img.shape[:2], dtype = \"uint8\")  \n","cv2.imshow(\"Vermelho\", cv2.merge([zeros, zeros, canalVermelho]))  \n","cv2.imshow(\"Verde\", cv2.merge([zeros, canalVerde, zeros])) \n","cv2.imshow(\"Azul\", cv2.merge([canalAzul, zeros, zeros])) \n","cv2.imshow(\"Original\", img) \n","cv2.waitKey(0) "],"metadata":{"id":"bISXII-2sISD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Histogramas e equalização de imagem  \n","\n","\n","\n","Um histograma é um gráfico de colunas ou de linhas que representa a distribuição dos valores dos pixels de uma imagem, ou seja, a quantidade de pixeis mais claros (próximos de 255) e a quantidade de pixels mais escuros (próximos de 0). O eixo X do gráfico normalmente possui uma distribuição de 0 a 255 que demonstra o valor (intensidade) do pixel e no eixo Y é plotada a quantidade de pixels daquela intensidade. \n","\n"],"metadata":{"id":"nrhColoYsNsH"}},{"cell_type":"code","source":["from matplotlib import pyplot as plt \n","import cv2  \n","img = cv2.imread('ponte.jpg') \n","img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #converte P&B \n","cv2.imshow(\"Imagem P&B\", img) \n","#Função calcHist para calcular o histograma da imagem \n","h = cv2.calcHist([img], [0], None, [256], [0, 256]) \n","plt.figure() \n","plt.title(\"Histograma P&B\") \n","plt.xlabel(\"Intensidade\") \n","plt.ylabel(\"Qtde de Pixels\") \n","plt.plot(h) \n","plt.xlim([0, 256]) \n","plt.show() \n","cv2.waitKey(0)  "],"metadata":{"id":"-NeeZczmsP4u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Também  é  possível  plotar  o  histograma  de  outra  forma,  com  a  ajuda  da  função ‘ravel()’. Neste caso o eixo X avança o valor 255 indo até 300, espaço que não existem pixels.  \n","\n"],"metadata":{"id":"KTuJnHbTsV0A"}},{"cell_type":"code","source":["plt.hist(img.ravel(),256,[0,256]) plt.show() "],"metadata":{"id":"y_uIKhX2sXey"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["lém do histograma da imagem em tons de cinza é possível plotar um histograma da imagem colorida. Neste caso teremos três linhas, uma para cada canal. Veja abaixo o código \n","\n","necessário.  Importante notar que a função ‘zip’ cria uma lista de tuplas formada  pelas  união das  listas  passadas  e  não  tem  nada  a  ver  com  um  processo  de  compactação  como  poderia  se esperar. \n","\n"],"metadata":{"id":"SuziP74FslFq"}},{"cell_type":"code","source":["from matplotlib import pyplot as plt\n","import numpy as np\n","import cv2\n","img = cv2.imread('ponte.jpg')\n","cv2.imshow(\"Imagem Colorida\", img)\n","#Separa os canais\n","canais = cv2.split(img)\n","cores = (\"b\", \"g\", \"r\")\n","plt.figure()\n","plt.title(\"'Histograma Colorido\")\n","plt.xlabel(\"Intensidade\")\n","plt.ylabel(\"Número de Pixels\")\n","for (canal, cor) in zip(canais, cores):\n","#Este loop executa 3 vezes, uma para cada canal\n","hist = cv2.calcHist([canal], [0], None, [256], [0, 256])\n","plt.plot(hist, cor = cor)\n","plt.xlim([0, 256])\n","plt.show() "],"metadata":{"id":"hPZ-3t37sp5e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Equalização de Histograma \n","\n","\n","É possível realizar um cálculo matemático sobre a distribuição de pixels para aumentar o contraste da imagem. A intenção neste caso é distribuir de forma mais uniforme as\n","intensidades dos pixels sobre a imagem. No histograma é possível identificar a diferença pois o acumulo de pixels próximo a alguns valores é suavizado. Veja a diferença entre o\n","histograma original e o equalizado abaixo:"],"metadata":{"id":"dc3Ir-T1stsb"}},{"cell_type":"code","source":["from matplotlib import pyplot as plt\n","import numpy as np\n","import cv2\n","img = cv2.imread('ponte.jpg')\n","img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","h_eq = cv2.equalizeHist(img)\n","plt.figure()\n","plt.title(\"Histograma Equalizado\")\n","plt.xlabel(\"Intensidade\")\n","plt.ylabel(\"Qtde de Pixels\")\n","plt.hist(h_eq.ravel(), 256, [0,256])\n","plt.xlim([0, 256])\n","plt.show()\n","plt.figure()\n","plt.title(\"Histograma Original\")\n","plt.xlabel(\"Intensidade\")\n","plt.ylabel(\"Qtde de Pixels\")\n","plt.hist(img.ravel(), 256, [0,256])\n","plt.xlim([0, 256])\n","plt.show()\n","cv2.waitKey(0) "],"metadata":{"id":"OMhQZFCksx_r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Suavização de imagens\n","\n","\n","A  suavização  da  imagem  (do  inglês  Smoothing),  também  chamada  de  ‘blur’  ou ‘blurring’ que podemos traduzir para “borrão”, é um efeito que podemos notar nas fotografias fora de foco ou desfocadas onde tudo fica embasado. Na  verdade  esse  efeito  pode  ser  criado  digitalmente,  basta  alterar  a  cor  de  cada  pixel misturando  a  cor  com  os  pixels  ao  seu  redor.  Esse  efeito  é  muito  útil  quando  utilizamos algoritmos  de  identificação  de  objetos  em  imagens  pois  os  processos  de  detecção  de  bordas por exemplo, funcionam melhor depois de aplicar uma suavização na imagem.\n","\n","Suavização por cálculo da média\n","\n","\n","\n"," Neste caso é criada uma “máscara para envolver o pixel em questão e calcular seu novo valor. O novo valor do pixel será a média simples dos valores dos pixels dentro da máscara,  ou  seja,  dos  pixels  da  vizinhança.  Alguns  autores  chamam  esta  máscara  de  janela  de cálculo ou kernel (do inglês núcleo).   \n","\n","\n","Portanto o novo valor do pixel será a média da sua vizinhança o que gera a suavização na imagem como um todo.  No código abaixo percebemos que o método utilizado para a suavização pela média é o  método  ‘blur’  da  OpenCV.  Os  parâmetros  são  a  imagem  a  ser  suavizada  e  a  janela  de suavização. Colocarmos números impars para gerar as caixas de cálculo pois dessa forma não existe dúvida sobre onde estará o pixel central que terá seu valor atualizado.  Perceba que usamos as funções vstack (pilha vertical) e hstack (pilha horizontal) para juntar as imagens em uma única imagem final mostrando desde a imagem original e seguinte com caixas de calculo de 3x3, 5x5, 7x7, 9x9 e 11x11. Perceba que conforme aumenta a caixa maior é o efeito de borrão (blur) na imagem.  "],"metadata":{"id":"7jKF899as1Rk"}},{"cell_type":"code","source":["img = cv2.imread('ponte.jpg') \n","img = img[::2,::2] # Diminui a imagem  \n","suave = np.vstack([   np.hstack([img,cv2.blur(img, ( 3,  3))]),np.hstack([cv2.blur(img, (5,5)), cv2.blur(img, ( 7,  7))]),np.hstack([cv2.blur(img, (9,9)), cv2.blur(img, (11, 11))]),])  \n","cv2.imshow(\"Imagens suavisadas (Blur)\", suave) \n","cv2.waitKey(0)  "],"metadata":{"id":"JcF5nnxxtE0m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Suavização pela mediana\n","\n","\n","Da  mesma  forma  que  os  cálculos  anteriores,  aqui  temos  o  cálculo  de  uma  caixa  ou  janela  quadrada  sobre  um  pixel  central  onde  matematicamente  se  utiliza  a  mediana  para \n","\n","calcular o valor final do pixel. A mediana é semelhante à média, mas ela despreza os valores muito altos ou muito baixos que podem distorcer o resultado. A mediana é o número que fica \n","\n","exatamente no meio do intervalo. A  função  utilizada  é  a  cv2.medianBlur(img,  3)  e  o  único  argumento  é  o  tamanho  da caixa ou janela usada. É importante notar que este método não cria novas cores, como pode acontecer com os anteriores, pois ele sempre altera a cor do pixel atual com um dos valores da vizinhança. \n","\n","Veja o código usado: \n","\n"],"metadata":{"id":"JtMcJnLatKdS"}},{"cell_type":"code","source":["import numpy as np\n","import cv2\n","img = cv2.imread('ponte.jpg')\n","img = img[::2,::2] # Diminui a imagem\n","suave = np.vstack([\n","np.hstack([img,\n","cv2.medianBlur(img,  3)]),\n","np.hstack([cv2.medianBlur(img,  5),\n","cv2.medianBlur(img,  7)]),\n","np.hstack([cv2.medianBlur(img,  9),\n","cv2.medianBlur(img, 11)]),\n","])\n","cv2.imshow(\"Imagem original e suavizadas pela mediana\", suave)\n","cv2.waitKey(0) "],"metadata":{"id":"_Gxk8gjqtMT0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Suavização com filtro bilateral  \n","\n","\n","Este  método  é  mais  lento  para calcular  que os  anteriores  mas  como  vantagem apresenta a preservação de bordas e garante que o ruído seja removido.  \n","\n","Para  realizar  essa  tarefa,  além  de  um  filtro  gaussiano  do  espaço  ao  redor  do  pixel também é utilizado outro cálculo com outro filtro gaussiano que leva em conta a diferença de \n","\n","intensidade  entre  os  pixels,  dessa  forma,  como  resultado  temos  uma  maior  manutenção  das bordas das imagem. A função usada é cv2.bilateralFilter() e o código usado segue abaixo: \n","\n"],"metadata":{"id":"BQdt9XgjtOlF"}},{"cell_type":"code","source":["img = cv2.imread('ponte.jpg')\n","img = img[::2,::2] # Diminui a imagem\n","suave = np.vstack([\n","np.hstack([img,\n","cv2.bilateralFilter(img,  3, 21, 21)]),\n","np.hstack([cv2.bilateralFilter(img,  5, 35, 35),\n","cv2.bilateralFilter(img,  7, 49, 49)]),\n","np.hstack([cv2.bilateralFilter(img,  9, 63, 63),\n","cv2.bilateralFilter(img, 11, 77, 77)])\n","]) "],"metadata":{"id":"vpNahD2GtXUM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Binarização com limiar\n","\n","\n","Thresholding  pode  ser  traduzido  por  limiarização  e  no  caso  de  processamento  de imagens  na  maior  parte  das  vezes  utilizamos  para  binarização  da  imagem.  Normalmente\n","convertemos  imagens  em  tons  de  cinza  para  imagens  preto  e  branco  onde  todos  os  pixels possuem 0 ou 255 como valores de intensidade.  \n","\n"],"metadata":{"id":"XxS-CfgwtbrF"}},{"cell_type":"code","source":["img = cv2.imread('ponte.jpg') \n","img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  \n","suave = cv2.GaussianBlur(img, (7, 7), 0) # aplica blur  \n","(T, bin) = cv2.threshold(suave, 160, 255, cv2.THRESH_BINARY) \n","(T, binI) = cv2.threshold(suave, 160, 255, cv2.THRESH_BINARY_INV) \n","resultado = np.vstack([  np.hstack([suave, bin]),  np.hstack([binI, cv2.bitwise_and(img, img, mask = binI)])  ])   \n","cv2.imshow(\"Binarização da imagem\", resultado) \n","cv2.waitKey(0) "],"metadata":{"id":"bBUwOnS4tev8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Threshold adaptativo  \n","\n","\n","O valor de intensidade 160 utilizada para a binarização acima foi arbitrado, contudo, é possível otimizar esse valor matematicamente. Esta é a proposta do threshold adaptativo.  \n","Para isso precisamos dar um valor da janela ou caixa de cálculo para que o limiar seja calculado nos pixels próximos das imagem. Outro parâmetro é um inteiro que é subtraído da\n","média calculada dentro da caixa para gerar o threshold final. "],"metadata":{"id":"AU8NteS_tnr2"}},{"cell_type":"code","source":["img = cv2.imread('ponte.jpg') \n","img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # converte  \n","suave = cv2.GaussianBlur(img, (7, 7), 0) # aplica blur   \n","bin1 = cv2.adaptiveThreshold(suave, 255,  cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 21, 5) \n","bin2 = cv2.adaptiveThreshold(suave, 255,  cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 21, 5)  \n","resultado = np.vstack([  np.hstack([img, suave]),  np.hstack([bin1, bin2])  ])   \n","cv2.imshow(\"Binarização adaptativa da imagem\", resultado) \n","cv2.waitKey(0)  "],"metadata":{"id":"1Pk12OrNtpGM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Threshold com Otsu e Riddler-Calvard\n","\n","\n","Outro método que automaticamente encontra um threshold para a imagem é o método de Otsu. Neste caso ele analiza o histograma da imagem para encontrar os dois maiores picos\n","de intensidades, então ele calcula um valor para separar da melhor forma esses dois picos."],"metadata":{"id":"qLArYkx_t1eG"}},{"cell_type":"code","source":["import mahotas \n","import numpy as np \n","import cv2  \n","img = cv2.imread('ponte.jpg') \n","img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # converte  \n","suave = cv2.GaussianBlur(img, (7, 7), 0) # aplica blur  \n","T = mahotas.thresholding.otsu(suave) \n","temp = img.copy() \n","temp[temp > T] = 255 \n","temp[temp < 255] = 0 \n","temp = cv2.bitwise_not(temp) \n","T = mahotas.thresholding.rc(suave) \n","temp2 = img.copy() \n","temp2[temp2 > T] = 255 \n","temp2[temp2 < 255] = 0 \n","temp2 = cv2.bitwise_not(temp2) \n","resultado = np.vstack([  np.hstack([img, suave]),  np.hstack([temp, temp2])  ])  \n","cv2.imshow(\"Binarização com método Otsu e Riddler-Calvard\", resultado) \n","cv2.waitKey(0) "],"metadata":{"id":"momhLG1at4B8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Sobel  \n","\n","\n","Não entraremos na explicação matemática de cada método mas é importante notar que o  Sobel  é  direcional,  então  temos  que  juntar  o  filtro  horizontal  e  o  vertical  para  ter  uma\n","transformação completa, veja: "],"metadata":{"id":"nAnSf8NJuAy4"}},{"cell_type":"code","source":["import numpy as np \n","import cv2  \n","img = cv2.imread('ponte.jpg') \n","img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  \n","sobelX = cv2.Sobel(img, cv2.CV_64F, 1, 0) \n","sobelY = cv2.Sobel(img, cv2.CV_64F, 0, 1) \n","sobelX = np.uint8(np.absolute(sobelX)) \n","sobelY = np.uint8(np.absolute(sobelY)) \n","sobel = cv2.bitwise_or(sobelX, sobelY)  \n","resultado = np.vstack([  np.hstack([img,    sobelX]),  np.hstack([sobelY, sobel])  ])   \n","cv2.imshow(\"Sobel\", resultado) \n","cv2.waitKey(0) "],"metadata":{"id":"saPXPqTBuCFY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Filtro Laplaciano\n","\n","O  filtro  Laplaciano  não  exige  processamento  individual  horizontal  e  vertical  como  o Sobel.  Um  único  passo  é  necessário  para  gerar  a  imagem  abaixo.  Contudo,  também  é \n","\n","necessário trabalhar com a representação do pixel em ponto flutuant de 64 bits com sinal para depois converter novamente para inteiro sem sinal de 8 bits. \n","\n"],"metadata":{"id":"7IIUvnxvuHWX"}},{"cell_type":"code","source":["import numpy as np \n","import cv2 \n","img = cv2.imread('ponte.jpg') \n","img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n","lap = cv2.Laplacian(img, cv2.CV_64F) \n","lap = np.uint8(np.absolute(lap)) \n","resultado = np.vstack([img, lap])  \n","cv2.imshow(\"Filtro Laplaciano\", resultado) \n","cv2.waitKey(0) "],"metadata":{"id":"UoFiGwFruKlZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Detector de bordas Canny  \n","Em inglês canny pode ser traduzido para esperto, esta no discionário. E o Carry Hedge Detector ou detector de bordas Caany realmente é mais inteligente que os outros. Na verdade \n","\n","ele  se  utiliza  de  outras  técnicas  como  o  Sobel  e  realiza  multiplos  passos  para  chegar  ao resultado final.  \n","\n","Basicamente o Canny envolve: \n","\n","1. Aplicar um filtro gaussiano para suavizar a imagem e remover o ruído. \n","\n","2. Encontrar os gradientes de intensidade da imagem. \n","\n","3. Aplicar Sobel duplo para determinar bordas potenciais. \n","\n","4. Aplicar o processo de “hysteresis” para verificar se o pixel faz parte de uma borda  “forte”  suprimindo todas as outras bordas que são fracas e não conectadas a bordas fortes.  \n","\n","É preciso fornecer dois parâmetros para a função  cv2.Canny(). Esses dois valores são o  limiar  1  e  limiar  2  e são utilizados no processo de “hysteresis” final.  Qualquer  gradiente \n","\n","com valor maior que o limiar 2 é considerado como borda. Qualquer valor inferior ao limiar 1 não é considerado borda. Valores entre o limiar 1 e limiar 2 são classificados como bordas ou \n","\n","não bordas com base em como eles estão conectados."],"metadata":{"id":"nZEW1bC5uPvE"}},{"cell_type":"code","source":["import numpy as np \n","import cv2 \n","img = cv2.imread('ponte.jpg') \n","img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n","suave = cv2.GaussianBlur(img, (7, 7), 0)  \n","canny1 = cv2.Canny(suave, 20, 120) \n","canny2 = cv2.Canny(suave, 70, 200) \n","resultado = np.vstack([  np.hstack([img,    suave ]),  np.hstack([canny1, canny2])  ])  \n","cv2.imshow(\"Detector de Bordas Canny\", resultado) \n","cv2.waitKey(0)"],"metadata":{"id":"X_Xp8PDWuTCz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Identificando e contando objetos\n","\n","\n","Como todos sabem, a atividade de jogar dados é muito útil. Muito útil para jogar RPG, General e outros jogos.  Mas depois do sistema apresentado abaixo, não será mais necessário\n","clicar no mouse ou pressionar uma tecla do teclado para jogar com o computador. Você poderá jogar os dados de verdade e o computador irá “ver” sua pontuação."],"metadata":{"id":"BFSgw4pJujL3"}},{"cell_type":"code","source":["import numpy as np \n","import cv2 \n","import mahotas  \n","#Função para facilitar a escrita nas imagem \n","def escreve(img, texto, cor=(255,0,0)):\n","  fonte = cv2.FONT_HERSHEY_SIMPLEX \n","  cv2.putText(img, texto, (10,20), fonte, 0.5, cor, 0,      cv2.LINE_AA)\n","imgColorida = cv2.imread('dados.jpg') #Carregamento da imagem  \n","#Se necessário o redimensioamento da imagem pode vir aqui.\n","#Passo 1: Conversão para tons de cinza \n","img = cv2.cvtColor(imgColorida, cv2.COLOR_BGR2GRAY)  \n","#Passo 2: Blur/Suavização da imagem \n","suave = cv2.blur(img, (7, 7))  \n","#Passo 3: Binarização resultando em pixels brancos e pretos \n","T = mahotas.thresholding.otsu(suave) \n","bin = suave.copy() bin[bin > T] = 255 \n","bin[bin < 255] = 0 \n","bin = cv2.bitwise_not(bin)  \n","#Passo 4: Detecção de bordas com Canny \n","bordas = cv2.Canny(bin, 70, 150)  \n","#Passo 5: Identificação e contagem dos contornos da imagem \n","#cv2.RETR_EXTERNAL = conta apenas os contornos externos \n","(lx, objetos, lx) = cv2.findContours(bordas.copy(),cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) #A variável lx (lixo) recebe dados que não são utilizados\n","escreve(img, \"Imagem em tons de cinza\", 0) \n","escreve(suave, \"Suavizacao com Blur\", 0) \n","escreve(bin, \"Binarizacao com Metodo Otsu\", 255) \n","escreve(bordas, \"Detector de bordas Canny\", 255)\n","temp = np.vstack([  np.hstack([img, suave]),   np.hstack([bin, bordas])   ])   \n","cv2.imshow(\"Quantidade de objetos: \"+str(len(objetos)), temp) \n","cv2.waitKey(0) \n","imgC2 = imgColorida.copy() \n","cv2.imshow(\"Imagem Original\", imgColorida)\n","cv2.drawContours(imgC2, objetos, -1, (255, 0, 0), 2) \n","escreve(imgC2, str(len(objetos))+\" objetos encontrados!\") \n","cv2.imshow(\"Resultado\", imgC2) \n","cv2.waitKey(0) "],"metadata":{"id":"LnyiImkyum3Q"},"execution_count":null,"outputs":[]}]}